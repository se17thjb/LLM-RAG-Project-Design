# Code Evaluation System for Programming Feedback using Retrieval-Augmented Generation Technology

An intelligent code evaluation and feedback system designed to help novice programmers learn Python fundamentals through AI-powered analysis and personalized guidance.

## üéØ Overview

This project implements a code evaluation system that leverages **Large Language Models (LLMs)** and **Retrieval-Augmented Generation (RAG)** technology to provide contextual, educational feedback on Python code submissions. Unlike traditional automated grading systems, our approach offers explanatory feedback that helps students understand not just what's wrong, but why and how to improve.

## ‚ú® Key Features

- **Intelligent Code Analysis**: Evaluates Python code for correctness, style, and best practices
- **RAG-Enhanced Feedback**: Retrieves relevant educational content and programming concepts to provide context-aware explanations
- **Personalized Learning**: Adapts feedback based on common beginner mistakes and learning patterns
- **Educational Focus**: Prioritizes teaching programming fundamentals over simple pass/fail grading

## üõ†Ô∏è Technologies Used

- **Large Language Models (LLMs)**: For natural language feedback generation and code understanding
- **RAG Framework**: To retrieve and integrate relevant programming documentation and examples
- **Python**: Core programming language for the system
- **[Additional Libraries]**: LangChain, ChromaDB/Pinecone, OpenAI API, Transformers

## üéì Use Cases

- Programming course assignments and exercises
- Self-paced learning platforms
- Coding bootcamps and workshops
- Supplementary tool for programming instructors

## üë• Team

Developed as part of academic research at **Technological Institute of the Philippines - Quezon City**  
**Duration**: September 2024 - June 2025
